{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOS7pdqFqwVBIjaOIgGlqpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolayLenkovNikolaev/Bayesian_Statistics/blob/main/L1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNhNVrB6hqU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semplici modelli per Inferenza Bayesiana\n",
        "\n",
        "## Introduzione:\n",
        "\n",
        "la regola di Bayes, come mostrato nel capitolo precedente, viene impiegata per determinare la distribuzione a posteriori del parametro.\n",
        "\n",
        "Le tre componenti dell'inferenza Bayesiana sono:\n",
        "- la probabilita iniziale\n",
        "- la verosimiglianza\n",
        "- la probabilita posteriori\n",
        "\n",
        "La **probabilita iniziale** (a priori) e' le funzione di densita/probabilita del vettore dei parametri che dipende (e' condizionata) dall'informazione iniziale (nel seguito quest'informazione iniziale si denota con H) e la prior come $p(\\theta|H)$\n",
        "\n",
        "Nel contesto sperimentale p osservazionale spesso si fanno ipotesi o congetture sul valore del parametro e questo permettono di stabilire una specifica forma funzionale per la distribuzione a priori\n",
        "\n",
        "Altre volte invece, qust'ultima viene fornita in base alle informazioni ricavate da studi precedenti e consolidate nella pratica del campo applicativo. Le informazioni a priori si integrano con quelle fornite dai dati e' linferenza si bassa sulla distribuzione a posteriori.\n",
        "\n",
        "In sitenesi:\n",
        "- si noti che distribuzione a posteriori e' una distribuzione di probabilita e la sua casualita e' il riflesso dell'incertezza sul parametro che si ha condizionatamente all'osservazione dei dati.\n",
        "- nell'inferenza classica $\\theta$ non e' una variabile casuale ma e' posto in relazione alla popolazione da cui vengono generati i dati attraverso i concetto di campionamento ripettuto.\n",
        "- mentre nell'inferenza Bayesiana non si valuta la variabilita di $\\hat{\\theta}$ con il campionamento ripetuto , quanto piuttosto si tenta di rispondere alla domanda: cosa devo supporre circa la distribuzione di $\\theta$ alla luce delle conoscenza attuali e dei dati osservati?\n",
        "\n",
        "Disponendo di dati $x = (x_1,...x_n)$ considerate come realizzazioni delle variabili casuali $X = (X_1...X_n)$ la probabilita a priori viene aggiornata in base alla verosimiglianza del modello statistico assunto per i dati e la distribuzione a priori viene aggiornata con la distribuzione a posteriori (posterior).\n",
        "\n",
        "Essendo:\n",
        "- equazione 1:\n",
        "$$p(\\theta|X, H)  = \\frac{p(\\theta, X|H)}{p(X|H)}= \\frac{p(X|\\theta, H).p(\\theta|X)}{p(X|H)}$$\n",
        "\n",
        "dove $p(X|H)= \\int_{\\theta} p(\\theta, X|H)d\\theta$ quando $\\theta$ ha un supporto $\\in R$\n",
        "\n",
        "\n",
        "La seguante caratteristiche della distribuzione a posteriri sono uitili per comunicare i risultati di un analisi Bayesiana come sintesi della distribuzione a posteriori. Rispetto ad un singolo numero si considera:\n",
        "- la media a spoteriori:\n",
        "$$E[\\theta, x_1...x_n] = \\int \\theta p(\\theta|x_1...x_n)d\\theta$$\n",
        "- la disttribuzione cumulata\n",
        "$$P(\\theta <a |x_1..x_n) = \\int I(\\theta)p(\\theta|x_1...x_n) d\\theta$$\n",
        "\n",
        "dove la funzione indicatrice I vale 1 se $\\theta <a$ e 0-altrimenti\n",
        "\n",
        "Ulteriore aspetto dell'inferenza Bayesiana riguarda la distribuzione preditiva che viene ricavata considerando la distribuzione a posteriori. Conoscendo $x_1...x_n$ si intende prevedere $x_{n+1}^*$ e si utilizza la seguente regola:\n",
        "$$p(x_{n+1}^*|x_1...x_n) = \\frac{p(x_1,...x_n, x_{n+1}^*)}{p(x_1..x_n)}$$\n",
        "\n",
        "dove sia il numeratore che il denominatore di questo rapporto sono funzioni relativamente complesse da determinare."
      ],
      "metadata": {
        "id": "BinEoFqYhr6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questa si calcola risolvendo il seguente integrale:\n",
        "$$p(x_{n+1}^*|x) = \\int p(x_{n+1}^* |\\theta, x).p(\\theta|x)d\\theta$$\n",
        "\n",
        "che non sempre e' risolvibile analiticamente se non per le famiglie di modelli che vengono definite coniugate.\n",
        "\n",
        "SI dispone del vettore $x=(x_1..x_n)$ do n-osservazioni che si interpretano come realizzazion della variabile casuale avente la distribzuione assunta per il modello statistico con parametri $\\theta =(\\theta_1,...\\theta_k)$\n",
        "\n",
        "Nell'inferenza Bayesiana il parametro e' visto come una variabile casuale e si assegna anche al parametro una disribuzione di densita o di proababilita\n",
        "\n",
        "Si esplicitano delle supposizioni sul parametro in base alle conoscenza sul problema oggetto di studio sviluppate fino ad un certo momento.\n",
        "\n",
        "E' possibile ricavare la distribuzione a posteriori ovvero la distribuzione dei parametri condizionati ai dati osservati e alle conoscenza a priori nel modo che segue:\n",
        "$$p(\\theta|x)= \\frac{p(x|\\theta)p(\\theta)}{p(x)}$$\n",
        "\n",
        "dove $p(x) = \\int p(x|\\theta)p(\\theta)d\\theta$ per $\\theta$ supporto continuo\n",
        "\n",
        "I valori osservati x sono fisi e partanto la densitaprobabilita $p(x|\\theta)$ e' funzione solo di $\\theta$ ed e' indicata anceh con $l(\\theta, x)$ (funzione di verosimilianza)\n",
        "$$p(\\theta|x) \\propto l(\\theta, x)p(\\theta)$$\n",
        "\n",
        "il risultato deve essere aggiustato cacolando la constante di normalizzazione k per far si che $p(\\theta|x)$ sia una funzione di densita/probabilita\n",
        "$$p(\\theta|x)= k.l(\\theta,x)p(\\theta)$$\n",
        "\n",
        "con il vincolo affinche sia una funzione di densita:\n",
        "$$1 = \\int_{\\Theta} k.l(\\theta,x)p(\\theta)d\\theta$$\n",
        "\\\n",
        "di cui $$\\frac{1}{k}= E_{\\theta}[l(\\theta,x)]$$\n",
        "- dove il valore attesso rappresenta la **distribuzione prevista** di X\n",
        "\n",
        "L'adeguatezza del modello statistico , ovvero una valutazione che permetta di quantificarne la validita, siverifica anche considerando la distribuzione preditiva e confrontando i valori realizzati rispeto quelli previsti.\n",
        "\n",
        "Attraverso opportune misure diagnostiche e' possibile verificare lo schema inferenzaiale adottato\n",
        "\n",
        "Se ad esempio si notano valori realizzati molto frequenti che avevano una probabilita piutosto bass occore riveder lo schema inferenziale adottato.\n",
        "\n",
        "SI noti che la distribuzione predittiva puio essere espressa nel modo che segue:\n",
        "\n",
        "$$p(x_{n+1}^*|x)= E[p(x_{n+1}^*, \\theta)|X]$$\n",
        "\n",
        "ovvero dipoende dai dati osservati: cio che si ooerva $x_1..x_n$ p[ermette di ricavare informazione sul parametro e questo a sua volta fornisce informazioni per prevedere il valore della risposta alla realizzazione successiva $x_{n+1}^*$\n",
        "\n",
        "d'alto canto la distibuzione predittiva $p(x_{x+1}^*, \\theta)$ per ogni punto dello spazio campionario e' il valore atteso a posteriori della distribuzione del modello assunto per le osservazioni campionarie (sampling distribution)\n",
        "\n"
      ],
      "metadata": {
        "id": "3cWrMcK1hr8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ragionamento sequenziale:\n",
        "prendento in considerazione la distribuzione a priori , la verosimiglianza e la densita a posteriori si puo mostrare la natura sequnziale del ragionamento Bayesiano\n",
        "\n",
        "Pertendo da un vettore di osservazioni $x_1=(x_{11}, ...xx_{1n})$\n",
        "$$p(\\theta,x_1) \\propto l_1(\\theta,x_1)p(\\theta)$$\n",
        "\n",
        "si considerano ulteriori realizzazioni $x_2= (x_{21})$"
      ],
      "metadata": {
        "id": "tVBwTCcNhr_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RqlE3g_ThsBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jNtuUscuhsEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ITqr3W8BhsGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tfePV1p_hsIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-jkQMkuShsK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qk3IyV9bhsNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o43fAe__hsPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Euf3xYI5hsRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GJPltQCIhsUC"
      }
    }
  ]
}